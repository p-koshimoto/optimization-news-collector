import arxiv
import feedparser
import requests
from datetime import datetime, timedelta
import json
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import sys
import pytz

class OptimizationNewsCollector:
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
        self.recipient_email = os.getenv('RECIPIENT_EMAIL')
        self.sender_email = os.getenv('SENDER_EMAIL')
        self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
        self.discord_webhook = os.getenv('DISCORD_WEBHOOK')
        
        # æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š
        self.jst = pytz.timezone('Asia/Tokyo')
        
    def get_jst_time(self):
        """ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
        return datetime.now(self.jst)
    
    def collect_arxiv_papers(self, days_back=1):
        """arXivã‹ã‚‰æ•°ç†æœ€é©åŒ–é–¢é€£è«–æ–‡ã‚’åé›†"""
        print("ğŸ“š arXivã‹ã‚‰è«–æ–‡ã‚’åé›†ä¸­...")
        
        try:
            # ã‚ˆã‚Šå…·ä½“çš„ãªæ•°ç†æœ€é©åŒ–é–¢é€£ã®ã‚¯ã‚¨ãƒª
            client = arxiv.Client()
            search = arxiv.Search(
                query=(
                    "cat:math.OC OR "
                    "(cat:cs.DM AND (ti:optimization OR ti:programming OR ti:algorithm)) OR "
                    "(cat:stat.ML AND ti:optimization) OR "
                    "ti:ã€Œlinear programmingã€ OR ti:ã€Œinteger programmingã€ OR "
                    "ti:ã€Œconvex optimizationã€ OR ti:ã€Œnonlinear programmingã€ OR "
                    "ti:ã€Œcombinatorial optimizationã€ OR ti:ã€Œstochastic optimizationã€"
                ),
                max_results=20,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )
            
            papers = []
            cutoff_date = self.get_jst_time().date() - timedelta(days=days_back)
            
            for result in client.results(search):
                # æ—¥æœ¬æ™‚é–“ã§ã®æ—¥ä»˜æ¯”è¼ƒ
                published_jst = result.published.astimezone(self.jst).date()
                if published_jst >= cutoff_date:
                    papers.append({
                        'title': result.title.replace('\n', ' ').strip(),
                        'authors': [author.name for author in result.authors[:3]],
                        'abstract': result.summary.replace('\n', ' ').strip()[:500] + "...",
                        'url': result.entry_id,
                        'published': published_jst.strftime('%Y-%m-%d'),
                        'categories': result.categories
                    })
            
            print(f"âœ… è«–æ–‡ {len(papers)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
            return papers
            
        except Exception as e:
            print(f"âŒ arXivåé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def collect_news_from_rss(self):
        """RSSã‹ã‚‰æœ€é©åŒ–é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰"""
        print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...")
        
        # æ•°ç†æœ€é©åŒ–ã«ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„RSSã‚½ãƒ¼ã‚¹
        rss_urls = [
            "https://rss.cnn.com/rss/edition_technology.rss",
            "https://feeds.reuters.com/reuters/technologyNews",
            "https://rss.slashdot.org/Slashdot/slashdotMain",
            "https://feeds.feedburner.com/oreilly/radar"
        ]
        
        # ã‚ˆã‚Šå³å¯†ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿
        optimization_keywords = [
            'optimization', 'optimisation', 'algorithm', 'programming',
            'linear programming', 'integer programming', 'convex',
            'machine learning', 'data science', 'operations research',
            'mathematical programming', 'solver', 'constraint',
            'heuristic', 'metaheuristic', 'genetic algorithm',
            'simulated annealing', 'particle swarm', 'gradient descent',
            'neural network', 'deep learning', 'reinforcement learning'
        ]
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé–¢é€£æ€§ã®ä½ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é™¤å¤–ï¼‰
        exclude_keywords = [
            'celebrity', 'entertainment', 'sports', 'weather',
            'politics', 'election', 'crime', 'accident', 'war',
            'fashion', 'food', 'travel', 'celebrity', 'gossip'
        ]
        
        news_items = []
        for rss_url in rss_urls:
            try:
                feed = feedparser.parse(rss_url)
                for entry in feed.entries[:10]:  # å„RSSã‹ã‚‰10ä»¶ãƒã‚§ãƒƒã‚¯
                    title_lower = entry.title.lower()
                    summary_lower = getattr(entry, 'summary', '').lower()
                    combined_text = title_lower + ' ' + summary_lower
                    
                    # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                    if any(exclude in combined_text for exclude in exclude_keywords):
                        continue
                    
                    # æœ€é©åŒ–é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ˆã‚Šå³å¯†ï¼‰
                    relevance_score = sum(1 for keyword in optimization_keywords 
                                        if keyword in combined_text)
                    
                    # é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãŒ2ä»¥ä¸Šã®è¨˜äº‹ã®ã¿æ¡ç”¨
                    if relevance_score >= 2:
                        # æ—¥æœ¬æ™‚é–“ã§å…¬é–‹æ—¥ã‚’å‡¦ç†
                        published_date = getattr(entry, 'published', '')
                        if published_date:
                            try:
                                pub_dt = datetime.strptime(published_date[:19], '%Y-%m-%dT%H:%M:%S')
                                pub_dt = pytz.utc.localize(pub_dt).astimezone(self.jst)
                                published_jst = pub_dt.strftime('%Y-%m-%d %H:%M JST')
                            except:
                                published_jst = published_date
                        else:
                            published_jst = 'æ—¥æ™‚ä¸æ˜'
                        
                        news_items.append({
                            'title': entry.title,
                            'link': entry.link,
                            'published': published_jst,
                            'summary': getattr(entry, 'summary', '')[:300] + "...",
                            'relevance_score': relevance_score
                        })
                        
                        # ååˆ†ãªæ•°ã®é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒé›†ã¾ã£ãŸã‚‰çµ‚äº†
                        if len(news_items) >= 8:
                            break
                            
            except Exception as e:
                print(f"âš ï¸ RSSå–å¾—ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}")
                continue
        
        # é–¢é€£åº¦ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        news_items.sort(key=lambda x: x['relevance_score'], reverse=True)
        news_items = news_items[:5]  # ä¸Šä½5ä»¶ã®ã¿
        
        print(f"âœ… é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(news_items)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
        return news_items
    
    def generate_simple_summary(self, text, max_sentences=2):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªè¦ç´„ç”Ÿæˆï¼ˆå¤–éƒ¨APIä¸ä½¿ç”¨ï¼‰"""
        sentences = text.split('.')
        summary_sentences = sentences[:max_sentences]
        return '. '.join(summary_sentences).strip() + '.'
    
    def generate_report(self, papers, news_items):
        """æ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆæ—¥æœ¬æ™‚é–“å¯¾å¿œï¼‰"""
        jst_now = self.get_jst_time()
        
        report = f"""
# ğŸ”¬ æ•°ç†æœ€é©åŒ– æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
**ç”Ÿæˆæ—¥æ™‚**: {jst_now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} JST

---

## ğŸ“š æ–°ç€è«–æ–‡ ({len(papers)}ä»¶)

"""
        
        if papers:
            for i, paper in enumerate(papers, 1):
                authors_str = ', '.join(paper['authors'])
                if len(paper['authors']) > 3:
                    authors_str += " ä»–"
                
                report += f"""
### {i}. {paper['title']}

- **è‘—è€…**: {authors_str}
- **ã‚«ãƒ†ã‚´ãƒª**: {', '.join(paper['categories'][:2])}
- **å…¬é–‹æ—¥**: {paper['published']}
- **æ¦‚è¦**: {paper['abstract']}
- **URL**: {paper['url']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯æ–°ç€è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“° æ•°ç†æœ€é©åŒ–é–¢é€£æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({len(news_items)}ä»¶)

"""
        
        if news_items:
            for i, news in enumerate(news_items, 1):
                report += f"""
### {i}. {news['title']}

- **è¦ç´„**: {news['summary']}
- **é–¢é€£åº¦**: {'â­' * news['relevance_score']}
- **ãƒªãƒ³ã‚¯**: {news['link']}
- **å…¬é–‹æ—¥**: {news['published']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“Š åé›†çµ±è¨ˆ
- è«–æ–‡æ•°: {len(papers)}ä»¶
- ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(news_items)}ä»¶
- ç”Ÿæˆæ™‚åˆ»: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ (JST: Japan Standard Time)*
"""
        
        return report
    
    def send_email_report(self, report):
        """Gmailã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é€ä¿¡"""
        if not all([self.sender_email, self.sender_password, self.recipient_email]):
            print("âŒ ãƒ¡ãƒ¼ãƒ«è¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return False
        
        try:
            msg = MIMEMultipart()
            msg['From'] = self.sender_email
            msg['To'] = self.recipient_email
            jst_now = self.get_jst_time()
            msg['Subject'] = f"ğŸ”¬ æ•°ç†æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ - {jst_now.strftime('%Y/%m/%d')} JST"
            
            msg.attach(MIMEText(report, 'plain', 'utf-8'))
            
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(self.sender_email, self.sender_password)
            text = msg.as_string()
            server.sendmail(self.sender_email, self.recipient_email, text)
            server.quit()
            
            print("âœ… ãƒ¡ãƒ¼ãƒ«ã§é€ä¿¡å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def send_discord_report(self, report):
        """Discord Webhookã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é€ä¿¡"""
        if not self.discord_webhook:
            print("âŒ Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            # Discordã®æ–‡å­—æ•°åˆ¶é™ï¼ˆ2000æ–‡å­—ï¼‰å¯¾å¿œ
            if len(report) > 1900:
                report = report[:1900] + "\n\n[ãƒ¬ãƒãƒ¼ãƒˆãŒé•·ã„ãŸã‚åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¾ã—ãŸ]"
            
            payload = {
                "content": f"```markdown\n{report}\n```"
            }
            
            response = requests.post(self.discord_webhook, json=payload)
            if response.status_code == 204:
                print("âœ… Discordã«é€ä¿¡å®Œäº†")
                return True
            else:
                print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def save_report_to_file(self, report):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæ—¥æœ¬æ™‚é–“ã§ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰"""
        jst_now = self.get_jst_time()
        filename = f"report_{jst_now.strftime('%Y%m%d_%H%M')}_JST.md"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            return filename
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_daily_collection(self):
        """æ—¥æ¬¡åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ"""
        jst_now = self.get_jst_time()
        
        print("=" * 50)
        print(f"ğŸš€ æ—¥æ¬¡åé›†é–‹å§‹: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿åé›†
        papers = self.collect_arxiv_papers(days_back=2)  # éå»2æ—¥åˆ†
        news_items = self.collect_news_from_rss()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_report(papers, news_items)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self.save_report_to_file(report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
        email_sent = self.send_email_report(report)
        discord_sent = self.send_discord_report(report)
        
        print("=" * 50)
        print("ğŸ“Š å®Ÿè¡Œçµæœ:")
        print(f"  ğŸ“š è«–æ–‡: {len(papers)}ä»¶")
        print(f"  ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_items)}ä»¶")
        print(f"  ğŸ“§ ãƒ¡ãƒ¼ãƒ«é€ä¿¡: {'âœ…' if email_sent else 'âŒ'}")
        print(f"  ğŸ’¬ Discordé€ä¿¡: {'âœ…' if discord_sent else 'âŒ'}")
        print(f"  ğŸ• å®Ÿè¡Œæ™‚åˆ»: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
        print("=" * 50)
        
        return {
            'papers_count': len(papers),
            'news_count': len(news_items),
            'email_sent': email_sent,
            'discord_sent': discord_sent,
            'execution_time_jst': jst_now.strftime('%Y-%m-%d %H:%M:%S JST')
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ æ•°ç†æœ€é©åŒ–è«–æ–‡ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    collector = OptimizationNewsCollector()
    result = collector.run_daily_collection()
    
    # çµæœã‚’JSONã§å‡ºåŠ›ï¼ˆGitHub Actionsã§ã®ç¢ºèªç”¨ï¼‰
    print("\nğŸ“„ å®Ÿè¡Œçµæœï¼ˆJSONï¼‰:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
