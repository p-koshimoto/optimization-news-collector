import arxiv
import feedparser
import requests
from datetime import datetime, timedelta
import json
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import sys

class OptimizationNewsCollector:
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
        self.recipient_email = os.getenv('RECIPIENT_EMAIL')
        self.sender_email = os.getenv('SENDER_EMAIL')
        self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
        self.discord_webhook = os.getenv('DISCORD_WEBHOOK')
        
    def collect_arxiv_papers(self, days_back=1):
        """arXivã‹ã‚‰æ•°ç†æœ€é©åŒ–é–¢é€£è«–æ–‡ã‚’åé›†"""
        print("ğŸ“š arXivã‹ã‚‰è«–æ–‡ã‚’åé›†ä¸­...")
        
        try:
            # æ•°ç†æœ€é©åŒ–é–¢é€£ã®ã‚«ãƒ†ã‚´ãƒªã§æ¤œç´¢
            client = arxiv.Client()
            search = arxiv.Search(
                query="cat:math.OC OR cat:cs.DM OR ti:optimization OR ti:programming",
                max_results=20,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )
            
            papers = []
            for result in client.results(search):
                # éå»Næ—¥ä»¥å†…ã®è«–æ–‡ã®ã¿
                if (datetime.now().date() - result.published.date()).days <= days_back:
                    papers.append({
                        'title': result.title.replace('\n', ' ').strip(),
                        'authors': [author.name for author in result.authors[:3]],  # æœ€åˆã®3å
                        'abstract': result.summary.replace('\n', ' ').strip()[:500] + "...",
                        'url': result.entry_id,
                        'published': result.published.strftime('%Y-%m-%d'),
                        'categories': result.categories
                    })
            
            print(f"âœ… è«–æ–‡ {len(papers)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
            return papers
            
        except Exception as e:
            print(f"âŒ arXivåé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def collect_news_from_rss(self):
        """RSSã‹ã‚‰æœ€é©åŒ–é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†"""
        print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...")
        
        # è¤‡æ•°ã®RSSã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨
        rss_urls = [
            "https://rss.cnn.com/rss/edition.rss",
            "https://feeds.reuters.com/reuters/technologyNews",
            "https://rss.slashdot.org/Slashdot/slashdotMain"
        ]
        
        news_items = []
        for rss_url in rss_urls:
            try:
                feed = feedparser.parse(rss_url)
                for entry in feed.entries[:5]:  # å„RSSã‹ã‚‰5ä»¶
                    # æœ€é©åŒ–é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿
                    title_lower = entry.title.lower()
                    if any(keyword in title_lower for keyword in [
                        'optimization', 'algorithm', 'ai', 'machine learning', 
                        'data science', 'research'
                    ]):
                        news_items.append({
                            'title': entry.title,
                            'link': entry.link,
                            'published': getattr(entry, 'published', ''),
                            'summary': getattr(entry, 'summary', '')[:300] + "..."
                        })
            except Exception as e:
                print(f"âš ï¸ RSSå–å¾—ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}")
                continue
        
        print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(news_items)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
        return news_items
    
    def generate_simple_summary(self, text, max_sentences=2):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªè¦ç´„ç”Ÿæˆï¼ˆå¤–éƒ¨APIä¸ä½¿ç”¨ï¼‰"""
        sentences = text.split('.')
        # æœ€åˆã®æ•°æ–‡ã‚’è¦ç´„ã¨ã—ã¦ä½¿ç”¨
        summary_sentences = sentences[:max_sentences]
        return '. '.join(summary_sentences).strip() + '.'
    
    def generate_report(self, papers, news_items):
        """æ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = f"""
# ğŸ”¬ æ•°ç†æœ€é©åŒ– æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}

---

## ğŸ“š æ–°ç€è«–æ–‡ ({len(papers)}ä»¶)

"""
        
        if papers:
            for i, paper in enumerate(papers, 1):
                authors_str = ', '.join(paper['authors'])
                if len(paper['authors']) > 3:
                    authors_str += " ä»–"
                
                report += f"""
### {i}. {paper['title']}

- **è‘—è€…**: {authors_str}
- **ã‚«ãƒ†ã‚´ãƒª**: {', '.join(paper['categories'][:2])}
- **å…¬é–‹æ—¥**: {paper['published']}
- **æ¦‚è¦**: {paper['abstract']}
- **URL**: {paper['url']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯æ–°ç€è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“° é–¢é€£æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({len(news_items)}ä»¶)

"""
        
        if news_items:
            for i, news in enumerate(news_items, 1):
                report += f"""
### {i}. {news['title']}

- **è¦ç´„**: {news['summary']}
- **ãƒªãƒ³ã‚¯**: {news['link']}
- **å…¬é–‹æ—¥**: {news['published']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“Š åé›†çµ±è¨ˆ
- è«–æ–‡æ•°: {len(papers)}ä»¶
- ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(news_items)}ä»¶
- ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""
        
        return report
    
    def send_email_report(self, report):
        """Gmailã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é€ä¿¡"""
        if not all([self.sender_email, self.sender_password, self.recipient_email]):
            print("âŒ ãƒ¡ãƒ¼ãƒ«è¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return False
        
        try:
            msg = MIMEMultipart()
            msg['From'] = self.sender_email
            msg['To'] = self.recipient_email
            msg['Subject'] = f"ğŸ”¬ æ•°ç†æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ - {datetime.now().strftime('%Y/%m/%d')}"
            
            msg.attach(MIMEText(report, 'plain', 'utf-8'))
            
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(self.sender_email, self.sender_password)
            text = msg.as_string()
            server.sendmail(self.sender_email, self.recipient_email, text)
            server.quit()
            
            print("âœ… ãƒ¡ãƒ¼ãƒ«ã§é€ä¿¡å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def send_discord_report(self, report):
        """Discord Webhookã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é€ä¿¡"""
        if not self.discord_webhook:
            print("âŒ Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            # Discordã®æ–‡å­—æ•°åˆ¶é™ï¼ˆ2000æ–‡å­—ï¼‰å¯¾å¿œ
            if len(report) > 1900:
                report = report[:1900] + "\n\n[ãƒ¬ãƒãƒ¼ãƒˆãŒé•·ã„ãŸã‚åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¾ã—ãŸ]"
            
            payload = {
                "content": f"```markdown\n{report}\n```"
            }
            
            response = requests.post(self.discord_webhook, json=payload)
            if response.status_code == 204:
                print("âœ… Discordã«é€ä¿¡å®Œäº†")
                return True
            else:
                print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def save_report_to_file(self, report):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        filename = f"report_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            return filename
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_daily_collection(self):
        """æ—¥æ¬¡åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ"""
        print("=" * 50)
        print(f"ğŸš€ æ—¥æ¬¡åé›†é–‹å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿åé›†
        papers = self.collect_arxiv_papers(days_back=2)  # éå»2æ—¥åˆ†
        news_items = self.collect_news_from_rss()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_report(papers, news_items)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self.save_report_to_file(report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
        email_sent = self.send_email_report(report)
        discord_sent = self.send_discord_report(report)
        
        print("=" * 50)
        print("ğŸ“Š å®Ÿè¡Œçµæœ:")
        print(f"  ğŸ“š è«–æ–‡: {len(papers)}ä»¶")
        print(f"  ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_items)}ä»¶")
        print(f"  ğŸ“§ ãƒ¡ãƒ¼ãƒ«é€ä¿¡: {'âœ…' if email_sent else 'âŒ'}")
        print(f"  ğŸ’¬ Discordé€ä¿¡: {'âœ…' if discord_sent else 'âŒ'}")
        print("=" * 50)
        
        return {
            'papers_count': len(papers),
            'news_count': len(news_items),
            'email_sent': email_sent,
            'discord_sent': discord_sent
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ æ•°ç†æœ€é©åŒ–è«–æ–‡ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    collector = OptimizationNewsCollector()
    result = collector.run_daily_collection()
    
    # çµæœã‚’JSONã§å‡ºåŠ›ï¼ˆGitHub Actionsã§ã®ç¢ºèªç”¨ï¼‰
    print("\nğŸ“„ å®Ÿè¡Œçµæœï¼ˆJSONï¼‰:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
