import arxiv
import feedparser
import requests
from datetime import datetime, timedelta
import json
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import os
import sys
import pytz
import time
from transformers import pipeline, M2M100ForConditionalGeneration, M2M100Tokenizer
import torch

class OptimizationNewsCollector:
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
        self.recipient_email = os.getenv('RECIPIENT_EMAIL')
        self.sender_email = os.getenv('SENDER_EMAIL')
        self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
        
        # æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š
        self.jst = pytz.timezone('Asia/Tokyo')

        # M2M100ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.setup_translation_model()
        
        # å„ªå…ˆåº¦ã®é«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç©ä»˜è¨ˆç”»æœ€é©åŒ–ã€é…é€è¨ˆç”»å•é¡Œã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å•é¡Œï¼‰
        self.priority_keywords = [
            'packing', 'bin packing', 'container packing', 'loading',
            'vehicle routing', 'delivery', 'distribution', 'logistics',
            'scheduling', 'task scheduling', 'job scheduling', 'resource scheduling',
            'timetabling', 'workforce scheduling'
        ]

    def setup_translation_model(self):
        """M2M100ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
        print("ğŸ”§ M2M100ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        cache_dir = os.getenv('TRANSFORMERS_CACHE', './model_cache')
        os.makedirs(cache_dir, exist_ok=True)
        
        try:
            # M2M100-418Mãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šé«˜ç²¾åº¦ï¼‰
            model_name = "facebook/m2m100_418M"
            
            # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãã†ã§ãªã‘ã‚Œã°CPUï¼‰
            device = 0 if torch.cuda.is_available() else -1
            
            # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å€‹åˆ¥ã«èª­ã¿è¾¼ã¿
            self.tokenizer = M2M100Tokenizer.from_pretrained(
                model_name,
                cache_dir=cache_dir
            )
            self.model = M2M100ForConditionalGeneration.from_pretrained(
                model_name,
                cache_dir=cache_dir
            )
            
            # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
            if torch.cuda.is_available():
                self.model = self.model.cuda()
                print("âœ… GPUä½¿ç”¨ã§M2M100ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            else:
                print("âœ… CPUä½¿ç”¨ã§M2M100ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                
        except Exception as e:
            print(f"âŒ M2M100åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™")
            try:
                self.translation_pipeline = pipeline(
                    "translation_en_to_ja", 
                    model="staka/fugumt-en-ja",
                    cache_dir=cache_dir
                )
                self.model = None
                self.tokenizer = None
                print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            except Exception as e2:
                print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¿»è¨³ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e2}")
                self.translation_pipeline = None
                self.model = None
                self.tokenizer = None
   
    def get_jst_time(self):
        """ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
        return datetime.now(self.jst)

    def translate_text(self, text, max_length=2048):
        """M2M100ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã‹ã‚‰æ—¥æœ¬èªã«ç¿»è¨³"""
        if not text or text.strip() == "":
            return ""
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        text = text.strip()
        if len(text) > 1000:  # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
            text = text[:1000] + "..."
        
        try:
            if self.model and self.tokenizer:
                # M2M100ã‚’ä½¿ç”¨ã—ãŸç¿»è¨³
                self.tokenizer.src_lang = "en"
                encoded = self.tokenizer(text, return_tensors="pt", max_length=512, truncation=True)
                
                # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
                if torch.cuda.is_available():
                    encoded = {k: v.cuda() for k, v in encoded.items()}
                
                # ç¿»è¨³å®Ÿè¡Œ
                generated_tokens = self.model.generate(
                    **encoded,
                    forced_bos_token_id=self.tokenizer.get_lang_id("ja"),
                    max_length=max_length,
                    num_beams=5,
                    early_stopping=True
                )
                
                translated = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
                return translated
                
            elif self.translation_pipeline:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¿»è¨³
                result = self.translation_pipeline(text, max_length=max_length)
                return result[0]['translation_text']
            else:
                # ç¿»è¨³ä¸å¯ã®å ´åˆ
                return "(ç¿»è¨³ä¸å¯)"
                
        except Exception as e:
            print(f"âš ï¸ ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
            return "(ç¿»è¨³å¤±æ•—)"

    def calculate_priority_score(self, title, summary=""):
        """å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆç©ä»˜è¨ˆç”»æœ€é©åŒ–ã€é…é€è¨ˆç”»å•é¡Œã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å•é¡Œã‚’æœ€å„ªå…ˆï¼‰"""
        combined_text = (title + " " + summary).lower()
        
        # å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        priority_score = 0
        for keyword in self.priority_keywords:
            if keyword in combined_text:
                priority_score += 10  # é«˜ã„å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢
        
        # ä¸€èˆ¬çš„ãªæœ€é©åŒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢
        general_keywords = [
            'optimization', 'optimisation', 'algorithm', 'programming',
            'linear programming', 'integer programming', 'convex',
            'mathematical programming', 'constraint', 'heuristic'
        ]
        
        for keyword in general_keywords:
            if keyword in combined_text:
                priority_score += 1
        
        return priority_score

    def simple_arxiv_test(self):
        """æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªarXivãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        print("æœ€æ–°5ä»¶ã® math.OC è«–æ–‡:")
        
        try:
            # Method 1: arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼ˆä¿®æ­£ç‰ˆï¼‰
            client = arxiv.Client()
            
            # ã‚ˆã‚Šå®‰å…¨ãªè¨­å®š
            search = arxiv.Search(
                query="cat:math.OC",
                max_results=5,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )
            
            # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§å®Ÿè¡Œ
            retry_count = 0
            max_retries = 3
            
            while retry_count < max_retries:
                try:
                    results = list(client.results(search))
                    break
                except (arxiv.arxiv.HTTPError, requests.exceptions.RequestException) as e:
                    retry_count += 1
                    print(f"  âš ï¸ è©¦è¡Œ {retry_count}/{max_retries} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    if retry_count < max_retries:
                        print(f"  â³ {2 ** retry_count}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                        time.sleep(2 ** retry_count)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    else:
                        print("  âŒ arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã‚’è©¦ã—ã¾ã™...")
                        return self.fallback_arxiv_test()
            
            for i, result in enumerate(results, 1):
                print(f"{i}. {result.title}")
                print(f"   Published: {result.published}")
                print(f"   URL: {result.entry_id}")
                print()
                
            print(f"âœ… arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ {len(results)} ä»¶å–å¾—æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
    def collect_arxiv_papers_fixed(self, days_back=2):
        """ä¿®æ­£ç‰ˆï¼šarXivã‹ã‚‰æ•°ç†æœ€é©åŒ–é–¢é€£è«–æ–‡ã‚’åé›†"""
        print("ğŸ“š arXivã‹ã‚‰è«–æ–‡ã‚’åé›†ä¸­...")
        
        papers = []
        cutoff_date = self.get_jst_time().date() - timedelta(days=days_back)
        
        # Method 1: arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è©¦ã™
        try:
            client = arxiv.Client()
            search = arxiv.Search(
                query=(
                    "cat:math.OC OR "
                    "(cat:cs.DM AND (optimization OR programming OR algorithm)) OR "
                    "(cat:stat.ML AND optimization) OR "
                    'ti:"linear programming" OR ti:"integer programming" OR '
                    'ti:"convex optimization" OR ti:"nonlinear programming" OR '
                    'ti:"combinatorial optimization" OR ti:"stochastic optimization" OR '
                    'ti:"packing" OR ti:"scheduling" OR ti:"vehicle routing"'
                ),
                max_results=50,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )
            
            # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§å®Ÿè¡Œ
            results = []
            retry_count = 0
            max_retries = 3
            
            while retry_count < max_retries:
                try:
                    results = list(client.results(search))
                    break
                except Exception as e:
                    retry_count += 1
                    print(f"  âš ï¸ arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªè©¦è¡Œ {retry_count}/{max_retries} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    if retry_count < max_retries:
                        time.sleep(2 ** retry_count)
                    else:
                        print("  âŒ arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¤±æ•—ã€ç›´æ¥APIå‘¼ã³å‡ºã—ã‚’è©¦ã—ã¾ã™...")
                        return self.collect_arxiv_papers_direct_api(days_back)
            
            # çµæœã‚’å‡¦ç†
            for result in results:
                published_jst = result.published.astimezone(self.jst).date()
                updated_jst = result.updated.astimezone(self.jst).date() if result.updated else None
                
                if published_jst >= cutoff_date or (updated_jst and updated_jst >= cutoff_date):
                    # ç¿»è¨³å®Ÿè¡Œ
                    print(f"  ğŸ“ ç¿»è¨³ä¸­: {result.title[:50]}...")
                    translated_title = self.translate_text(result.title)
                    translated_summary = self.translate_text(result.summary)
                    
                    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
                    priority_score = self.calculate_priority_score(result.title, result.summary)

                    papers.append({
                        'title': translated_title,
                        'original_title': result.title.replace('\n', ' ').strip(),
                        'authors': [author.name for author in result.authors[:3]],
                        'abstract': translated_summary,
                        'original_abstract': result.summary.replace('\n', ' ').strip()[:500] + "...",
                        'url': result.entry_id,
                        'published': published_jst.strftime('%Y-%m-%d'),
                        'updated': updated_jst.strftime('%Y-%m-%d') if updated_jst else None,
                        'categories': result.categories,
                        'priority_score': priority_score
                    })
            
            print(f"âœ… arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§è«–æ–‡ {len(papers)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
            return papers
            
        except Exception as e:
            print(f"âŒ arxivãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚¨ãƒ©ãƒ¼: {e}")
            print("ç›´æ¥APIå‘¼ã³å‡ºã—ã‚’è©¦ã—ã¾ã™...")
            return papers

    def collect_news_from_rss_improved(self):
        """æ”¹å–„ç‰ˆï¼šRSSã‹ã‚‰æœ€é©åŒ–é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†"""
        print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...")
        
        # ã‚ˆã‚Šç¾åœ¨ã§ã‚‚ä½¿ãˆã‚‹RSSã‚½ãƒ¼ã‚¹ï¼ˆ2024å¹´å¯¾å¿œï¼‰
        rss_urls = [
            # ã‚ˆã‚Šç¢ºå®Ÿã«å‹•ä½œã™ã‚‹RSSãƒ•ã‚£ãƒ¼ãƒ‰
            "https://www.theverge.com/rss/index.xml",
            "https://techcrunch.com/feed/",
            "https://www.wired.com/feed/rss",
            "https://arstechnica.com/feed/",
            "https://feeds.feedburner.com/venturebeat/SZYF",
            "https://www.zdnet.com/news/rss.xml"
        ]
#            "https://rss.cnn.com/rss/edition_technology.rss",    #ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼
#            "https://feeds.reuters.com/reuters/technologyNews"    #ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼

        
        # ã‚ˆã‚ŠæŸ”è»Ÿãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
        # Tier 1: ç›´æ¥é–¢é€£ï¼ˆé«˜ã‚¹ã‚³ã‚¢ï¼‰
        high_priority_keywords = [
            'optimization', 'optimisation', 'algorithm', 'programming',
            'machine learning', 'AI', 'artificial intelligence',
            'data science', 'operations research', 'solver'
        ]
        
        # Tier 2: é–“æ¥é–¢é€£ï¼ˆä¸­ã‚¹ã‚³ã‚¢ï¼‰
        medium_priority_keywords = [
            'analytics', 'efficiency', 'performance', 'automation',
            'neural network', 'deep learning', 'model', 'prediction',
            'computational', 'mathematical', 'statistical'
        ]
        
        # Tier 3: æŠ€è¡“é–¢é€£ï¼ˆä½ã‚¹ã‚³ã‚¢ï¼‰
        low_priority_keywords = [
            'software', 'technology', 'tech', 'innovation',
            'research', 'development', 'computing', 'digital'
        ]
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¸›ã‚‰ã™ï¼ˆéåº¦ãªé™¤å¤–ã‚’é˜²ãï¼‰
        exclude_keywords = [
            'celebrity', 'entertainment', 'sports', 'weather',
            'crime', 'accident', 'war', 'fashion', 'food', 'travel'
        ]
        
        news_items = []
        
        for rss_url in rss_urls:
            try:
                print(f"  ğŸ” å–å¾—ä¸­: {rss_url}")
                
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­å®š
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                # ã¾ãšHTTPã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                try:
                    response = requests.get(rss_url, headers=headers, timeout=10)
                    if response.status_code != 200:
                        print(f"    âš ï¸ HTTP {response.status_code}: {rss_url}")
                        continue
                except Exception as e:
                    print(f"    âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                
                # feedparserã§è§£æ
                feed = feedparser.parse(rss_url)
                
                if not feed.entries:
                    print(f"    âš ï¸ ã‚¨ãƒ³ãƒˆãƒªãªã—: {rss_url}")
                    continue
                
                print(f"    âœ… {len(feed.entries)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—")
                
                # ã‚ˆã‚Šå¤šãã®ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ20ä»¶ã«å¢—åŠ ï¼‰
                for entry in feed.entries[:20]:
                    try:
                        title_lower = entry.title.lower()
                        summary_lower = getattr(entry, 'summary', '').lower()
                        combined_text = title_lower + ' ' + summary_lower
                        
                        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆç·©å’Œï¼‰
                        exclude_count = sum(1 for exclude in exclude_keywords 
                                          if exclude in combined_text)
                        if exclude_count >= 2:  # 2å€‹ä»¥ä¸Šã®é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã®ã¿é™¤å¤–
                            continue
                        
                        # æ®µéšçš„é–¢é€£åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
                        high_score = sum(4 for keyword in high_priority_keywords 
                                       if keyword in combined_text)
                        medium_score = sum(2 for keyword in medium_priority_keywords 
                                         if keyword in combined_text)
                        low_score = sum(1 for keyword in low_priority_keywords 
                                      if keyword in combined_text)
                        
                        total_relevance_score = high_score + medium_score + low_score
                        
                        # ã‚ˆã‚Šç·©ã„é–¾å€¤ï¼ˆ2.0ä»¥ä¸Šã§æ¡ç”¨ï¼‰
                        if total_relevance_score >= 2.0:
                            # æ—¥æœ¬æ™‚é–“ã§å…¬é–‹æ—¥ã‚’å‡¦ç†
                            published_date = getattr(entry, 'published', '')
                            if published_date:
                                try:
                                    # ã‚ˆã‚ŠæŸ”è»Ÿãªæ—¥ä»˜ãƒ‘ãƒ¼ã‚¹
                                    from dateutil import parser
                                    pub_dt = parser.parse(published_date)
                                    if pub_dt.tzinfo is None:
                                        pub_dt = pytz.utc.localize(pub_dt)
                                    published_jst = pub_dt.astimezone(self.jst).strftime('%Y-%m-%d %H:%M JST')
                                except:
                                    published_jst = published_date[:19] if len(published_date) > 19 else published_date
                            else:
                                published_jst = 'æ—¥æ™‚ä¸æ˜'
                            
                            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆURLãƒ™ãƒ¼ã‚¹ï¼‰
                            if not any(item['link'] == entry.link for item in news_items):
                                # ç¿»è¨³å®Ÿè¡Œ
                                print(f"    ğŸ“ ç¿»è¨³ä¸­: {entry.title[:50]}...")
                                translated_title = self.translate_text(entry.title)
                                translated_summary = self.translate_text(getattr(entry, 'summary', ''))

                                news_items.append({
                                    'title': translated_title,
                                    'original_title': entry.title.strip(),
                                    'link': entry.link,
                                    'published': published_jst,
                                    'summary': translated_summary,
                                    'original_summary': getattr(entry, 'summary', '')[:300] + "...",
                                    'relevance_score': round(total_relevance_score, 1),
                                    'priority_score': priority_score,
                                    'source_url': rss_url
                                })
                                
                                print(f"    ğŸ“„ æ¡ç”¨: {entry.title[:50]}... (ã‚¹ã‚³ã‚¢: {total_relevance_score:.1f})")
                    
                    except Exception as e:
                        print(f"    âš ï¸ ã‚¨ãƒ³ãƒˆãƒªå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                        
            except Exception as e:
                print(f"  âŒ RSSå–å¾—ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}")
                continue
            
            # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            time.sleep(0.5)
        
        # é–¢é€£åº¦ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        news_items.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        # ä¸Šä½10ä»¶ã«åˆ¶é™ï¼ˆå…ƒã®5ä»¶ã‹ã‚‰å¢—åŠ ï¼‰
        news_items = news_items[:10]
        
        print(f"âœ… é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(news_items)} ä»¶ã‚’åé›†ã—ã¾ã—ãŸ")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
        if news_items:
            print("ğŸ“Š åé›†ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è©³ç´°:")
            for i, item in enumerate(news_items, 1):
                print(f"  {i}. ã‚¹ã‚³ã‚¢{item['relevance_score']}: {item['title'][:60]}...")
        else:
            print("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒ0ä»¶ã§ã™ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
            print("  1. RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ã‚¢ã‚¯ã‚»ã‚¹çŠ¶æ³")
            print("  2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ã®è¨­å®š")
            print("  3. é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¨­å®š")
        
        return news_items
    
    def generate_html_report(self, papers, news_items):
        """ç¾ã—ã„HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        jst_now = self.get_jst_time()
        
        # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        html_report = f"""
        <!DOCTYPE html>
        <html lang="ja">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>æ•°ç†æœ€é©åŒ– æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ</title>
            <style>
                body {{
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                    line-height: 1.6;
                    margin: 0;
                    padding: 20px;
                    background-color: #f5f5f5;
                    color: #333;
                }}
                .container {{
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: white;
                    border-radius: 10px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                    overflow: hidden;
                }}
                .header {{
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                    padding: 30px;
                    text-align: center;
                }}
                .header h1 {{
                    margin: 0;
                    font-size: 28px;
                    font-weight: 300;
                }}
                .header .date {{
                    margin-top: 10px;
                    font-size: 16px;
                    opacity: 0.9;
                }}
                .section {{
                    margin: 20px;
                }}
                .section-title {{
                    font-size: 22px;
                    font-weight: 600;
                    margin: 30px 0 20px 0;
                    padding: 15px;
                    border-radius: 8px;
                    display: flex;
                    align-items: center;
                }}
                .section-title.papers {{
                    background-color: #e3f2fd;
                    border-left: 5px solid #2196f3;
                    color: #1976d2;
                }}
                .section-title.news {{
                    background-color: #fff8e1;
                    border-left: 5px solid #ff9800;
                    color: #f57c00;
                }}
                .item {{
                    background-color: white;
                    border: 1px solid #e0e0e0;
                    border-radius: 8px;
                    margin: 15px 0;
                    padding: 20px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.05);
                    transition: box-shadow 0.3s ease;
                }}
                .item:hover {{
                    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                }}
                .item-title {{
                    font-size: 18px;
                    font-weight: 600;
                    margin-bottom: 12px;
                    color: #2c3e50;
                    line-height: 1.4;
                }}
                .item-meta {{
                    display: flex;
                    flex-wrap: wrap;
                    gap: 15px;
                    margin-bottom: 12px;
                    font-size: 14px;
                    color: #666;
                }}
                .meta-item {{
                    display: flex;
                    align-items: center;
                }}
                .meta-label {{
                    font-weight: 600;
                    margin-right: 5px;
                }}
                .abstract {{
                    color: #555;
                    line-height: 1.6;
                    margin-bottom: 15px;
                }}
                .link {{
                    display: inline-block;
                    background-color: #4CAF50;
                    color: white;
                    padding: 8px 16px;
                    text-decoration: none;
                    border-radius: 4px;
                    font-size: 14px;
                    transition: background-color 0.3s ease;
                }}
                .link:hover {{
                    background-color: #45a049;
                }}
                .news-link {{
                    background-color: #ff9800;
                }}
                .news-link:hover {{
                    background-color: #f57c00;
                }}
                .relevance-stars {{
                    color: #ffc107;
                    font-size: 16px;
                }}
                .stats {{
                    background-color: #f8f9fa;
                    border-radius: 8px;
                    padding: 20px;
                    margin: 30px 20px;
                    text-align: center;
                }}
                .stats-grid {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
                    gap: 20px;
                    margin-top: 15px;
                }}
                .stat-item {{
                    text-align: center;
                }}
                .stat-number {{
                    font-size: 24px;
                    font-weight: 700;
                    color: #2196f3;
                }}
                .stat-label {{
                    font-size: 14px;
                    color: #666;
                    margin-top: 5px;
                }}
                .footer {{
                    text-align: center;
                    padding: 20px;
                    color: #999;
                    font-size: 12px;
                    border-top: 1px solid #eee;
                }}
                .no-content {{
                    text-align: center;
                    padding: 40px;
                    color: #999;
                    font-style: italic;
                }}
                .emoji {{
                    margin-right: 8px;
                }}
                @media (max-width: 600px) {{
                    .container {{
                        margin: 10px;
                        border-radius: 5px;
                    }}
                    .header {{
                        padding: 20px;
                    }}
                    .header h1 {{
                        font-size: 24px;
                    }}
                    .section {{
                        margin: 15px;
                    }}
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ”¬ æ•°ç†æœ€é©åŒ– æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ</h1>
                    <div class="date">{jst_now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} JST</div>
                </div>
                
                <div class="section">
                    <div class="section-title papers">
                        <span class="emoji">ğŸ“š</span>
                        æ–°ç€è«–æ–‡ ({len(papers)}ä»¶)
                    </div>
        """
        
        # è«–æ–‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if papers:
            for i, paper in enumerate(papers, 1):
                authors_str = ', '.join(paper['authors'])
                if len(paper['authors']) > 3:
                    authors_str += " ä»–"
                
                categories_str = ', '.join(paper['categories'][:2])
                
                html_report += f"""
                    <div class="item">
                        <div class="item-title">{i}. {paper['title']}</div>
                        <div class="item-meta">
                            <div class="meta-item">
                                <span class="meta-label">ğŸ‘¥ è‘—è€…:</span>
                                {authors_str}
                            </div>
                            <div class="meta-item">
                                <span class="meta-label">ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒª:</span>
                                {categories_str}
                            </div>
                            <div class="meta-item">
                                <span class="meta-label">ğŸ“… å…¬é–‹æ—¥:</span>
                                {paper['published']}
                            </div>
                        </div>
                        <div class="abstract">{paper['abstract']}</div>
                        <a href="{paper['url']}" class="link" target="_blank">è«–æ–‡ã‚’èª­ã‚€</a>
                    </div>
                """
        else:
            html_report += '<div class="no-content">æœ¬æ—¥ã¯æ–°ç€è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</div>'
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        html_report += f"""
                </div>
                
                <div class="section">
                    <div class="section-title news">
                        <span class="emoji">ğŸ“°</span>
                        æ•°ç†æœ€é©åŒ–é–¢é€£æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({len(news_items)}ä»¶)
                    </div>
        """
        
        if news_items:
            for i, news in enumerate(news_items, 1):
                stars = 'â­' * int(news['relevance_score'])
                
                html_report += f"""
                    <div class="item">
                        <div class="item-title">{i}. {news['title']}</div>
                        <div class="item-meta">
                            <div class="meta-item">
                                <span class="meta-label">ğŸ¯ é–¢é€£åº¦:</span>
                                <span class="relevance-stars">{stars}</span>
                            </div>
                            <div class="meta-item">
                                <span class="meta-label">ğŸ“… å…¬é–‹æ—¥:</span>
                                {news['published']}
                            </div>
                        </div>
                        <div class="abstract">{news['summary']}</div>
                        <a href="{news['link']}" class="link news-link" target="_blank">è¨˜äº‹ã‚’èª­ã‚€</a>
                    </div>
                """
        else:
            html_report += '<div class="no-content">æœ¬æ—¥ã¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</div>'
        
        # çµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        html_report += f"""
                </div>
                
                <div class="stats">
                    <h3>ğŸ“Š åé›†çµ±è¨ˆ</h3>
                    <div class="stats-grid">
                        <div class="stat-item">
                            <div class="stat-number">{len(papers)}</div>
                            <div class="stat-label">è«–æ–‡æ•°</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-number">{len(news_items)}</div>
                            <div class="stat-label">ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-number">{jst_now.strftime('%H:%M')}</div>
                            <div class="stat-label">ç”Ÿæˆæ™‚åˆ» (JST)</div>
                        </div>
                    </div>
                </div>
                
                <div class="footer">
                    ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ<br>
                    æ—¥æœ¬æ¨™æº–æ™‚ (JST) - {jst_now.strftime('%Y-%m-%d %H:%M:%S')}
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_report
    
    def generate_text_report(self, papers, news_items):
        """ãƒ†ã‚­ã‚¹ãƒˆç‰ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆDiscordç”¨ãªã©ï¼‰"""
        jst_now = self.get_jst_time()
        
        report = f"""
# ğŸ”¬ æ•°ç†æœ€é©åŒ– æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
**ç”Ÿæˆæ—¥æ™‚**: {jst_now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} JST

---

## ğŸ“š æ–°ç€è«–æ–‡ ({len(papers)}ä»¶)

"""
        
        if papers:
            for i, paper in enumerate(papers, 1):
                authors_str = ', '.join(paper['authors'])
                if len(paper['authors']) > 3:
                    authors_str += " ä»–"
                
                report += f"""
### {i}. {paper['title']}

- **è‘—è€…**: {authors_str}
- **ã‚«ãƒ†ã‚´ãƒª**: {', '.join(paper['categories'][:2])}
- **å…¬é–‹æ—¥**: {paper['published']}
- **æ¦‚è¦**: {paper['abstract']}
- **URL**: {paper['url']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯æ–°ç€è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“° æ•°ç†æœ€é©åŒ–é–¢é€£æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({len(news_items)}ä»¶)

"""
        
        if news_items:
            for i, news in enumerate(news_items, 1):
                report += f"""
### {i}. {news['title']}

- **è¦ç´„**: {news['summary']}
- **é–¢é€£åº¦**: {'â­' * int(news['relevance_score'])}
- **ãƒªãƒ³ã‚¯**: {news['link']}
- **å…¬é–‹æ—¥**: {news['published']}

---
"""
        else:
            report += "\næœ¬æ—¥ã¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n---\n"
        
        report += f"""

## ğŸ“Š åé›†çµ±è¨ˆ
- è«–æ–‡æ•°: {len(papers)}ä»¶
- ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(news_items)}ä»¶
- ç”Ÿæˆæ™‚åˆ»: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ (JST: Japan Standard Time)*
"""
        
        return report
    
    def send_email_report(self, html_report, text_report):
        """HTMLã¨ãƒ†ã‚­ã‚¹ãƒˆä¸¡æ–¹ã«å¯¾å¿œã—ãŸãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡"""
        if not all([self.sender_email, self.sender_password, self.recipient_email]):
            print("âŒ ãƒ¡ãƒ¼ãƒ«è¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return False
        
        try:
            # ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            msg = MIMEMultipart('alternative')
            msg['From'] = self.sender_email
            msg['To'] = self.recipient_email
            jst_now = self.get_jst_time()
            msg['Subject'] = f"ğŸ”¬ æ•°ç†æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ - {jst_now.strftime('%Y/%m/%d')} JST"
            
            # ãƒ†ã‚­ã‚¹ãƒˆç‰ˆã¨HTMLç‰ˆã®ä¸¡æ–¹ã‚’æ·»ä»˜
            text_part = MIMEText(text_report, 'plain', 'utf-8')
            html_part = MIMEText(html_report, 'html', 'utf-8')
            
            msg.attach(text_part)
            msg.attach(html_part)
            
            # SMTPé€ä¿¡
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(self.sender_email, self.sender_password)
            text = msg.as_string()
            server.sendmail(self.sender_email, self.recipient_email, text)
            server.quit()
            
            print("âœ… HTMLãƒ¡ãƒ¼ãƒ«ã§é€ä¿¡å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def send_discord_report(self, report):
        """Discord Webhookã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é€ä¿¡"""
        if not self.discord_webhook:
            print("âŒ Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            # Discordã®æ–‡å­—æ•°åˆ¶é™ï¼ˆ2000æ–‡å­—ï¼‰å¯¾å¿œ
            if len(report) > 1900:
                report = report[:1900] + "\n\n[ãƒ¬ãƒãƒ¼ãƒˆãŒé•·ã„ãŸã‚åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¾ã—ãŸ]"
            
            payload = {
                "content": f"```markdown\n{report}\n```"
            }
            
            response = requests.post(self.discord_webhook, json=payload)
            if response.status_code == 204:
                print("âœ… Discordã«é€ä¿¡å®Œäº†")
                return True
            else:
                print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def save_report_to_file(self, html_report, text_report):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆHTMLç‰ˆã¨ãƒ†ã‚­ã‚¹ãƒˆç‰ˆä¸¡æ–¹ï¼‰"""
        jst_now = self.get_jst_time()
        timestamp = jst_now.strftime('%Y%m%d_%H%M')
        
        html_filename = f"report_{timestamp}_JST.html"
        text_filename = f"report_{timestamp}_JST.md"
        
        try:
            # HTMLç‰ˆã‚’ä¿å­˜
            with open(html_filename, 'w', encoding='utf-8') as f:
                f.write(html_report)
            print(f"âœ… HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ {html_filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ãƒ†ã‚­ã‚¹ãƒˆç‰ˆã‚’ä¿å­˜
            with open(text_filename, 'w', encoding='utf-8') as f:
                f.write(text_report)
            print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ {text_filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            return html_filename, text_filename
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def run_daily_collection(self):
        """æ—¥æ¬¡åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ"""
        jst_now = self.get_jst_time()
        
        print("=" * 50)
        print(f"ğŸš€ æ—¥æ¬¡åé›†é–‹å§‹: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
        print("=" * 50)

#        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
#        test_success = self.simple_arxiv_test()
#        if not test_success:
#            print("âš ï¸ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æœ¬æ ¼åé›†ã‚’ç¶šè¡Œã—ã¾ã™...")

        
        # ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆä¿®æ­£ç‰ˆã‚’ä½¿ç”¨ï¼‰
        papers = self.collect_arxiv_papers_fixed(days_back=2)  # 2æ—¥åˆ†
#        news_items = self.collect_news_from_rss()
        news_items = self.collect_news_from_rss_improved()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆHTMLç‰ˆã¨ãƒ†ã‚­ã‚¹ãƒˆç‰ˆï¼‰
        html_report = self.generate_html_report(papers, news_items)
        text_report = self.generate_text_report(papers, news_items)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self.save_report_to_file(html_report, text_report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
        email_sent = self.send_email_report(html_report, text_report)
        
        print("=" * 50)
        print("ğŸ“Š å®Ÿè¡Œçµæœ:")
        print(f"  ğŸ“š è«–æ–‡: {len(papers)}ä»¶")
        print(f"  ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_items)}ä»¶")
        print(f"  ğŸ“§ HTMLãƒ¡ãƒ¼ãƒ«é€ä¿¡: {'âœ…' if email_sent else 'âŒ'}")
        print(f"  ğŸ• å®Ÿè¡Œæ™‚åˆ»: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
        print("=" * 50)
        
        return {
            'papers_count': len(papers),
            'news_count': len(news_items),
            'email_sent': email_sent,
            'execution_time_jst': jst_now.strftime('%Y-%m-%d %H:%M:%S JST')
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ æ•°ç†æœ€é©åŒ–è«–æ–‡ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)

    collector = OptimizationNewsCollector()
    result = collector.run_daily_collection()
    
    # çµæœã‚’JSONã§å‡ºåŠ›ï¼ˆGitHub Actionsã§ã®ç¢ºèªç”¨ï¼‰
    print("\nğŸ“„ å®Ÿè¡Œçµæœï¼ˆJSONï¼‰:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
